{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Chatbot Engine",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyyRUFxokYGH"
      },
      "source": [
        "# !pip install tflearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejhteDveDW5F"
      },
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tflearn\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import nltk\n",
        "# nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuLUY7HJ1gx2"
      },
      "source": [
        "with open('intents.json') as file:\n",
        "    intents = json.load(file, strict = False) \n",
        "intents = intents['intents'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0gvDT7A2nwV"
      },
      "source": [
        "print(\"[\", end = \"\")\n",
        "for intent in intents:\n",
        "  print(\"{\", end = \"\")\n",
        "  for key, value in intent.items():\n",
        "    print(\"{}: {},\".format(key, value))\n",
        "  print(\"\\b\\b\\n},\")\n",
        "print(\"\\b\\b]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNPimb9-kL_I"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvIb70C8kYtM"
      },
      "source": [
        "retrain_model = True\n",
        "\n",
        "if retrain_model:\n",
        "    P_all = [] #all patterns\n",
        "    T_all = [] #all tags\n",
        "    patterns = [] #patterns\n",
        "    tags = [] #tags\n",
        "    \n",
        "    for intent in intents:\n",
        "        for p in intent['patterns']:\n",
        "            words = nltk.word_tokenize(p)\n",
        "\n",
        "            P_all.extend(words)\n",
        "            patterns.append(words)\n",
        "            tags.append(intent['tag'])\n",
        "            \n",
        "        T_all.append(intent['tag'])\n",
        "      \n",
        " \n",
        "    P_all = [stemmer.stem(word.lower()) for word in P_all]\n",
        "    P_all = sorted(list(set(P_all)))\n",
        "    \n",
        "    T_all = sorted(T_all)\n",
        "    \n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    \n",
        "    y_empty = [0 for i in range(len(T_all))]\n",
        "    \n",
        "\n",
        "    for index, intent in enumerate(patterns):\n",
        "        words_set = []\n",
        "        \n",
        "        all_words = [stemmer.stem(word.lower()) for word in intent]\n",
        "        \n",
        "        for word in P_all:\n",
        "            if word in all_words:\n",
        "                words_set.append(1)\n",
        "            else:\n",
        "                words_set.append(0)\n",
        "                \n",
        "        out = y_empty[:]\n",
        "        out[T_all.index(tags[index])] = 1\n",
        "        \n",
        "        x_train.append(words_set)\n",
        "        y_train.append(out)\n",
        "    \n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    with open('training_data.pickle', 'wb') as f:\n",
        "        pickle.dump((P_all, T_all, x_train, y_train), f)\n",
        "else:\n",
        "    with open('training_data.pickle', 'rb') as f:\n",
        "        P_all, T_all, x_train, y_train = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yoCs-c6qiuS"
      },
      "source": [
        "# !pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckSETlJPluc1"
      },
      "source": [
        "# tf.reset_default_graph()\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "\n",
        "nn = tflearn.input_data(shape = [None, len(x_train[0])])\n",
        "nn = tflearn.fully_connected(nn, 8)\n",
        "nn = tflearn.fully_connected(nn, 8)\n",
        "\n",
        "nn = tflearn.fully_connected(nn, len(y_train[0]), activation = 'softmax')\n",
        "nn = tflearn.regression(nn)\n",
        "\n",
        "model = tflearn.DNN(nn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmUtrneXlvWf"
      },
      "source": [
        "if retrain_model:\n",
        "    model.fit(x_train, y_train, n_epoch = 1000, batch_size = 8, show_metric = True)\n",
        "    model.save('model.tfl')\n",
        "else:\n",
        "    model.load('./model.tfl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQtvD_EkRrD_"
      },
      "source": [
        "def text_set(t, P_all):\n",
        "    words_set = [0 for i in range(len(P_all))]\n",
        "    \n",
        "    text = nltk.word_tokenize(t)\n",
        "    text = [stemmer.stem(word.lower()) for word in text]\n",
        "    \n",
        "    for word in text:\n",
        "        if word in P_all:\n",
        "            words_set[P_all.index(word)] = 1\n",
        "    \n",
        "    return np.array(words_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKsYmRq8lxjU"
      },
      "source": [
        "def chat():\n",
        "    print(\"Enter a message to talk to the bot [type stop to exit].\")\n",
        "    \n",
        "    context = None\n",
        "    \n",
        "    default = ['Sorry, Im not sure I know what you mean! You could try rephrasing that!',\n",
        "                         'I dont understand that! Try rephrasing it.']\n",
        "\n",
        "    while True:\n",
        "        user = str(input('You: '))\n",
        "        if user.lower() == 'stop':\n",
        "            break\n",
        "        \n",
        "        user_set = text_set(user, P_all)\n",
        "\n",
        "        res = model.predict([user_set])[0]\n",
        "\n",
        "        res_index = np.argmax(res)\n",
        "        res_tag = T_all[res_index]\n",
        "        \n",
        "\n",
        "        if res[res_index] > 0.8:\n",
        "            for intent in intents:\n",
        "                if intent['tag'] == res_tag:\n",
        "                    if 'context_filter' not in intent or 'context_filter' in intent and intent['context_filter'] == context:\n",
        "                        outcomes = intent['responses']\n",
        "                        if 'context_set' in intent:\n",
        "                            context = intent['context_set']\n",
        "                        else:\n",
        "                            context = None\n",
        "                        print(random.choice(outcomes))\n",
        "                    else:\n",
        "                        print(random.choice(default))\n",
        "        else:\n",
        "            print(random.choice(default))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu9liIl4l16e"
      },
      "source": [
        "chat()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}